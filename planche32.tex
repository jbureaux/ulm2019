\chapter{Caractérisation de l'exponentielle}

\section{Sujet}

\paragraph{Premier exercice}
Soit $f : \mathbb{R} \rightarrow  \mathbb{C}$ une fonction développable en série entière en tout point. On suppose que la suite $f^{(n)}$ converge simplement vers $g$ lorsque $n\rightarrow \infty $. Trouver $g$.

\paragraph{Deuxième exercice}
Soit $n > 2$ un entier. On considère deux matrices $A, B \in  \mathscr{M} _{n} (\mathbb{R})$. On suppose que $B^2  = B$. Montrer que $\operatorname{rg}(AB -BA) \leqslant  \operatorname{rg}(AB + BA)$.

\paragraph{Troisème exercice}
\emph{L’exercice supplémentaire suivant a parfois été posé :} trouver une condition nécessaire et suffisante pour qu'une fonction $f : [-1, 0] \rightarrow  \mathbb{R}$ soit limite uniforme sur $[-1, 0]$ de polynômes à coefficients positifs.

\section{Solution du premier exercice}

On fixe $x\in \mathbb{R}.$

Soit $a\in \mathbb{R}.$

On a (a priori localement, au voisinage de $x$) comme $f$ est analytique sur $\mathbb{R}$
$$f(a)=\sum_{k\geq 0}\frac{f^{(k)}(x)}{k!}(a-x)^{k}.$$

\textbf{Remarque :} On peut remarquer que la série précédente est absolument convergente pour tout $a\in \mathbb{R},$ car : $$\vert \frac{f^{(k)}(x)}{k!}(a-x)^{k}\vert \sim \frac{\vert g(x) \vert }{k!}\vert x-a\vert^{k},$$ qui est manifestement le terme général d'une série convergente. 

Ainsi, $f$ est DSE en tout point et le rayon de convergence de sa série de Taylor est infini en tout point (et la somme de sa série de Taylor ne peut être que $f$).\\
%Ce dernier point n'est d'ailleurs pas si immédiat et nécessite à ma connaissance l'utilisation du théorème de Baire : cette remarque constitue un théorème du à Pringsheim dont une preuve rapide (due à W. Rudin) est fondée sur une variante affaiblie d'un théorème de Bernstein (cf planche 6).

%Ainsi, on note encore la limite de la série de Taylor notée $f.$\\

Soit $\varepsilon>0.$

Par hypothèse, on a pour $k\geq k_{0}\gg 1,$ : $$\vert g(x)-f^{(k)}(x)\vert \leq \varepsilon.$$

Ainsi, il vient pour $a\gg 1$
\begin{align*}
f(a)-g(x)e^{a-x} & =\sum_{0\leq k< k_{0}}\frac{f^{(k)}(x)-g(x)}{k!}(a-x)^{k}+\sum_{k\geq k_{0}}\frac{f^{(k)}(x)-g(x)}{k!}(a-x)^{k}\\
\mbox{ et donc, } \vert e^{-a}f(a)-g(x)e^{-x}\vert & \leq M(k_{0},x)\vert a-x\vert^{k_{0}}e^{-a}+\varepsilon e^{-x}.
\end{align*}

En faisant tendre $a$ vers $+\infty,$ il vient par croissances comparées :  $$\limsup_{a\rightarrow +\infty}\vert e^{-a}f(a)-g(x)e^{-x}\vert\leq \varepsilon e^{-x}.$$

Puis, en faisant tendre $\varepsilon$ vers $0,$ il vient : $$\lim_{a\rightarrow +\infty} e^{-a}f(a)=g(x)e^{-x}.$$

Comme ce raisonnement est vrai pour tout $x,$ on obtient par unicité des limites $$\forall x\in \mathbb{R},\mbox{ } g(x)e^{-x}=g(0) \mbox{ i.e. } g(x)=g(0)e^{x}.$$

%\textbf{Remarque : } On peut également traiter un énoncé légèrement modifié où la fonction $f$ est seulement supposée $C^{\infty}$ mais la limite simple $g$ un peu plus régulière...

%On va utiliser le lemme de Baire et aussi supposer que $g$ est $C^{1}$... 

%\begin{itemize}
%\item Soit $R>0.$

%Notons pour $n\geq 1,$ $$A_{n}=\left\{x \in  [-R,R]\mbox{ }|\mbox{ } \forall k\geq 0,\mbox{ } \vert f^{(k)}(x)\vert \leq n \right\}.$$

%Par continuité de chacune des applications $f^{(k)},$ $A_{n}$ est donc un fermé de $[-R,R].$

%Comme $\displaystyle \bigcup_{n\geq 1}A_{n}=[-R,R],$ il existe $n_{0}$ tel que $A_{n_{0}}$ soit d'intérieur non vide et même, à nouveau par une application du lemme de Baire, $\mathcal{U}:=\displaystyle \bigcup_{n\geq 1}\mbox{Int}(A_{n})$ est un ouvert dense de $[-R,R].$

%\item Soit $x\in\mathcal{U}.$ 

%Il existe alors $r>0$ tel que $I_{x}:=[x-r,x+r]\subset A_{n}$ pour un certain $n\geq 1.$

%Soit $y\in I_{x}.$ 

%On a alors pour tout $k\geq 0,$ $$f^{(k)}(y)-f^{(k)}(x-r)=\int_{x-r}^{y}f^{(k+1)}(t)dt.$$ Par convergence dominée, on obtient alors $\displaystyle g(y)-g(x-r)=\int_{x-r}^{y}g(t)dt.$

%Il vient alors en dérivant la relation précédente : $g'(y)=g(y).$ 

%\item On a alors $g'=g$ sur $\mathcal{U}.$ Comme $g$ est $C^{1}$ et que l'ouvert $\mathcal{U}$ est dense dans $[-R,R],$ on obtient $g'=g$ sur $[-R,R].$

%Le raisonnement précédent étant valide pour tout $R>0,$ on a alors $g'=g$ sur $\mathbb{R}.$

%Et ainsi, il existe $\lambda\in \mathbb{C}$ tel que pour tout $x\in\mathbb{R},$ $\displaystyle g(x)=\lambda e^{x}.$
%\end{itemize}

\paragraph{Autre solution} %Siméon
On va montrer que $g$ est partout dérivable, de dérivée $g'=g$, en établissant un développement limité à l'odre 1 au voisinage de tout point. Cette équation différentielle caractérise les multiples de la fonction exponentielle.

Soit $a \in \mathbb R$. Par hypothèse, il existe un réel $r > 0$ tel que $f$ coïncide avec son développement en série de Taylor sur $\left]a-r,a+r\right[$ :
\[
\forall x \in \left]-r,r\right[,\quad f(a+x) = \sum_{k=0}^\infty \frac{f^{(k)}(a)}{k!}x^k,
\]
avec un rayon de convergence minoré par $r$. Notons $M$ le réel $\sup_n |f^{(n)}(a)|$. En dérivant terme à terme le développement précédent, on obtient :
\[
\forall n\in\mathbb N,\forall x \in \left]-r,r\right[,\quad |f^{(n+2)}(a+x)| \leqslant \sum_{k=0}^\infty \frac{M}{k!}r^k = Me^{r}.
\]
L'inégalité de Taylor-Lagrange $\left|f^{(n)}(a+x) - f^{(n)}(a) -  f^{(n+1)}(a)\,x\right| \leqslant \frac{Me^{r}}2 x^2$ donne alors par passage à la limite lorsque $n \to \infty$ :
\[
\forall x \in \left]-r,r\right[,\quad g(a+x) = g(a) + g(a) x + O(x^2),
\]
d'où le résultat annoncé.


\section{Solution du deuxième exercice}

Voici une preuve d'algèbre linéaire "intrinsèque."\\

Comme $B$ est un projecteur (i.e. $B^{2}=B$), on a la décomposition en somme directe : $\displaystyle E=E_{0}\bigoplus E_{1}$ où $E_{0}$ désigne le noyau de $B$ et $E_{1}$ l'ensemble des points fixes de $B.$

On décompose alors $A$ en $A=P+Q$ où $P : E\rightarrow E_{0}$ et $Q : E\rightarrow E_{1}.$

Soit $(u,v)\in E_{0}\times E_{1}.$

On a alors 
\begin{align*}
(AB-BA)(u+v) & = AB(u+v)-BA(u+v)\\
& = Av-Q(u+v)\\
& = (A-Q)v-Qu\\
& =Pv-Qu.
\end{align*}

Ainsi, l'image de $AB-BA$ est $\displaystyle P(E_{1})\bigoplus Q(E_{0}).$

De même, on obtient : 

\begin{align*}
(AB+BA)(u+v) & = AB(u+v)+BA(u+v)\\
& = Av+Q(u+v)\\
& = (P+2Q)v+Qu.
\end{align*}

Ainsi, l'image de $AB+BA$ est $\displaystyle (P+2Q)(E_{1})+Q(E_{0}).$

Considérons alors une famille finie $(v_{i})_{i\in I}$ de vecteurs de $E_{1}$ telle que $(P(v_{i}))_{i\in I}$ soit une base de $P(E_{1}).$

Et, considérons également une famille finie $(u_{j})_{j\in J}$ de vecteurs de $E_{0}$ telle que $(Q(u_{j}))_{j\in J}$ soit une base de $Q(E_{0}).$

Alors, la famille $\{((P+2Q)(v_{i})_{i\in I};(Q(u_{j}))_{j\in J}\}$ est une famille libre de $E.$

Et ainsi, $\boxed{\displaystyle \mbox{Rg}(AB+BA)\geq \mbox{Rg}(AB-BA).}$

En effet, soit $(\alpha_{i})_{i\in I}$ et $(\beta_{j})_{j\in J}$ tels que $$\sum_{i\in I}\alpha_{i}(P+2Q)(v_{i})+\sum_{j\in J}\beta_{j}Q(u_{j})=0.$$

En projetant cette relation sur $E_{0},$ il vient $\displaystyle \sum_{i\in I}\alpha_{i}P(v_{i})=0.$ 

Et donc, $$\forall i\in I,\mbox{ } \alpha_{i}=0,$$ car $(P(v_{i}))_{i\in I}$ est une base de $P(E_{1}).$

Ainsi, on obtient : $\displaystyle \sum_{j\in J}\beta_{j}Q(u_{j})=0.$

Mais, comme $Q(u_{j}))_{j\in J}$ est une base de $Q(E_{0}),$ il s'ensuit : $$\forall j\in J,\mbox{ } \beta_{j}=0.$$  


\section{Solution du troisième exercice} % Calli

Nous allons montrer que $f(0) \geqslant  0$ est une condition nécessaire et suffisante.\\

\underline{$\Rightarrow $\,:} Supposons qu'il existe une suite $(P_{n} )$ de polynômes à coefficients positifs qui converge uniformément vers $f$ sur $[-1,0]$. Alors $f(0) =\displaystyle \lim _{n\rightarrow \infty } P_{n} (0) \geqslant 0$ car les $P_{n}$ ont tous un coefficient constant positif.\\

\underline{$\Leftarrow$\,:} Supposons que $f(0) \geqslant 0$. Soit $\varepsilon >0$. D'après le théorème de Weierstrass, il existe $P\in \mathbb{R}[X]$ tel que $\|P-f\|_{\infty } <\varepsilon $. Ecrivons $P = \sum_{k=0}^d a_{k} X^{k}$.

Si $a_{0} <0$, alors en posant $Q = \sum_{k=1}^d a_{k} X^{k}$, on a par positivité de $f(0)$ : \[\|Q -f\|_{\infty } \leqslant  \|Q -P\|_{\infty } + \|P-f\|_{\infty } < |a_{0} | +\varepsilon  \leqslant  f(0)-a_{0}  +\varepsilon  < 2\varepsilon .\]
Donc, quitte à remplacer $P$ par $Q$, on peut supposer $P(0) \geqslant 0$ et $\|P-f\|_{\infty } <2\varepsilon $.

Il faut maintenant approcher tous les $a_{k} X^{k}$ pour lesquels $a_{k} <0$ et $k>0$ par des polynômes à coefficients positifs. En écrivant $a_{k} X^{k} = -a_{k} X^{k-1} \cdot (-X)$, on voit qu'il suffit d'approcher $-X$ par des polynômes à coefficients positifs. Les polynômes $X(1+X)^{n} -X$ conviennent car, en développant le produit, on constate qu'ils ont bien des coefficients positifs et, par étude de fonction, le maximum de $|x(1+x)^{n} |$ sur $[-1,0]$ vaut $ \frac{1}{n+1} \left( 1- \frac{1}{n+1} \right)^{n} \leqslant  \frac{1}{n+1} \longrightarrow 0$.

Ainsi, il existe des polynômes à coefficients positifs $(R_{k} )$ tels que
\[\left\|\displaystyle \sum _{1\leqslant k\leqslant d,\,a_{k} <0} |a_{k} |X^{k-1} \cdot R_{k} - \sum _{1\leqslant k\leqslant d,\,a_{k} <0} a_{k} X^{k} \right\|_{\infty } <\varepsilon .\]
D'où : \[\left\| \left( \sum _{1\leqslant k\leqslant d,\,a_{k} <0} |a_{k} |X^{k-1} \cdot R_{k} + \sum _{1\leqslant k\leqslant d,\,a_{k} \geqslant 0} a_{k} X^{k} \right) - f\, \right\|_{\infty } <3\varepsilon .\]